from flask import Flask, request, jsonify
import joblib
import pandas as pd
import numpy as np
import traceback
import logging
import os
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Configuration des logs
logging.basicConfig(level=logging.INFO)

app = Flask(__name__)

# D√©finir le chemin du mod√®le
MODEL_PATH = "deployment/final_model.pkl"

# Charger le mod√®le en toute s√©curit√©
if os.path.exists(MODEL_PATH):
    try:
        model = joblib.load(MODEL_PATH)
        logging.info("‚úÖ Mod√®le charg√© avec succ√®s !")
    except Exception as e:
        logging.error(f"‚ùå Erreur lors du chargement du mod√®le : {str(e)}")
        model = None
else:
    logging.error(f"‚ùå Mod√®le introuvable √† l'emplacement : {MODEL_PATH}")
    model = None

@app.route('/predict', methods=['POST'])
def predict():
    if model is None:
        return jsonify({"error": "Mod√®le non charg√© ou introuvable"}), 500
    
    try:
        data = request.get_json()
        logging.info(f"üîπ Requ√™te re√ßue : {data}")

        if not isinstance(data, list):
            return jsonify({"error": "Les donn√©es doivent √™tre une liste de dictionnaires"}), 400

        df = pd.DataFrame(data)
        logging.info(f"üîπ Donn√©es converties en DataFrame :\n{df.head()}")

        # Pr√©traitement des donn√©es
        df = preprocess_data(df)
        logging.info(f"üîπ Donn√©es apr√®s preprocessing :\n{df.head()}")

        # V√©rifier si les colonnes correspondent √† celles du mod√®le
        model_features = model.feature_names_in_ if hasattr(model, "feature_names_in_") else df.columns
        missing_for_model = [col for col in model_features if col not in df.columns]
        if missing_for_model:
            return jsonify({"error": "Colonnes manquantes apr√®s pr√©traitement", "missing_features": missing_for_model}), 400
        
        df = df[model_features]

        # Pr√©diction
        prediction = model.predict(df)
        return jsonify({"prediction": prediction.tolist()})
    
    except Exception as e:
        logging.error(f"‚ùå Erreur lors de la pr√©diction : {str(e)}", exc_info=True)
        return jsonify({"error": "Erreur interne du serveur"}), 500

def preprocess_data(df):
    """Applique les transformations n√©cessaires avant d'envoyer les donn√©es au mod√®le."""
    df = df.copy()
    
    # Feature Engineering
    df['avg_monthly_charge'] = df['TotalCharges'] / (df['tenure'] + 1)
    df['is_long_term_contract'] = (df['Contract'] == 'Two year').astype(int)
    df['num_services'] = df[['PhoneService', 'MultipleLines', 'InternetService', 
                             'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 
                             'TechSupport', 'StreamingTV', 'StreamingMovies']].apply(
        lambda row: sum(1 for x in row if x in ['Yes', 'Fiber optic']), axis=1)
    
    # Suppression des colonnes inutiles
    drop_columns = ['CustomerID', 'gender', 'PhoneService', 'tenure', 'MonthlyCharges',
                    'OnlineSecurity_No internet service', 'OnlineBackup_No internet service',
                    'StreamingMovies_No internet service', 'StreamingTV_No internet service',
                    'TechSupport_No internet service', 'DeviceProtection_No internet service',
                    'InternetService_No']
    df.drop(columns=[col for col in drop_columns if col in df.columns], errors='ignore', inplace=True)
    
    # Encodage des variables cat√©goriques
    categorical_features = df.select_dtypes(include=['object']).columns
    for col in categorical_features:
        if df[col].nunique() == 2:
            df[col] = LabelEncoder().fit_transform(df[col])
        else:
            df = pd.get_dummies(df, columns=[col], drop_first=True)
    
    # S'assurer que toutes les colonnes du mod√®le sont pr√©sentes
    model_features = model.feature_names_in_ if hasattr(model, "feature_names_in_") else []
    for col in model_features:
        if col not in df.columns:
            df[col] = 0  # Ajouter les colonnes manquantes avec valeur 0
    
    # R√©organiser les colonnes dans le bon ordre
    df = df[model_features]
    
    # Normalisation
    scaler = StandardScaler()
    columns_to_scale = ['TotalCharges', 'avg_monthly_charge', 'num_services']
    df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])
    
    # Gestion des valeurs manquantes
    df.fillna(df.select_dtypes(include=[np.number]).median(), inplace=True)
    
    return df

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
